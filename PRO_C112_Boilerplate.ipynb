{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mssnowy/c112/blob/main/PRO_C112_Boilerplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVe_ge-0KTVn"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "**Image Dataset Directory Structur**e:\n",
        "\n",
        "**Note: The directory and sub-directory names shown here are only for explanation purposes which might differ from the code.**\n",
        "\n",
        "Suppose if we have a master directory(folder) of the Images then we can subdivide it into “Training”, “Validation” & “Testing” images sub-directories(sub-folder). \n",
        "\n",
        "And then the “Training” directories contain sub-directories(sub-folders) called “Infected” and “Uninfected” which contain appropriate images in the respective sub-directories.\n",
        "\n",
        "Similarly, the “Validation'' & “Testing” directory also contains sub-directories(sub-folders) called “Infected” and “Uninfected” which contain appropriate images in the respective sub-directories.\n",
        "\n",
        "\n",
        "**Training**: Images in this directory will be used for the training of the data.\n",
        "\n",
        "**Validation**: Images in this directory will be used to validate the model training. The validation dataset allows us to see how well the data generalises the classification.\n",
        "\n",
        "**Testing**: Images in this directory will be used to test how well the model is trained.\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/2467514a-e93f-4a0f-8e20-b3893dfa9144.jpeg\" width= 600>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xCYT8gXKTVq",
        "outputId": "92ab7571-3356-4658-9f3d-166b4878b912"
      },
      "source": [
        "!git clone https://github.com/procodingclass/PRO-M3-Pneumothorax-Image-Dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PRO-M3-Pneumothorax-Image-Dataset'...\n",
            "remote: Enumerating objects: 637, done.\u001b[K\n",
            "remote: Total 637 (delta 0), reused 0 (delta 0), pack-reused 637\u001b[K\n",
            "Receiving objects: 100% (637/637), 231.39 MiB | 26.29 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Updating files: 100% (601/601), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0nG4OkcN26G"
      },
      "source": [
        "## Image Preprocessing\n",
        "\n",
        "1. Convert each image to an array\n",
        "2. Map each image labels\n",
        "3. Augment the each image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtXxDq1O4okc"
      },
      "source": [
        "### Image Preprocessing: Mapping each image with labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DIAsjUd343_"
      },
      "source": [
        "<center><b>Mapping Each Image With Labels</b><br><img src=\"https://s3-whjr-curriculum-uploads.whjr.online/1bdade80-2a32-4fc2-8902-f18067803dba.jpeg\" width= 1000>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6cHrlB-5xQ4"
      },
      "source": [
        "### Image Preprocessing: Data Augmentation\n",
        "\n",
        "A few Data Augemtation Techniques:\n",
        "\n",
        "*   Image Rotation\n",
        "*   Image Height & Width Shift\n",
        "*   Image Horizontal & Vertical Flipping\n",
        "*   Image Resizing\n",
        "*   Image Zooming\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/5403e9b1-a339-405d-98b3-36826ec3f04a.gif\" width= 400>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NhJWjpUVBpu"
      },
      "source": [
        "#### Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5-_nrO7yn2D",
        "outputId": "98404f98-1535-4b38-8f20-7d127795d186"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "# Random Data Augmentation(Rescale, Rotation, Flips, Zoom, Shifts) using ImageDataGenerator \n",
        "training_data_generator = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "# Image Directory\n",
        "training_image_directory = \"/content/PRO-M3-Pneumothorax-Image-Dataset/training_dataset\"\n",
        "\n",
        "# Generate Preprocessed Augmented Data\n",
        "training_augmented_images = training_data_generator.flow_from_directory(\n",
        "    training_image_directory,\n",
        "    target_size=(180,180))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUOaQFdFVGmT"
      },
      "source": [
        "#### Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS-Jx1EB-OFg",
        "outputId": "c94edf46-1194-44db-e3bb-5e07f39dd222"
      },
      "source": [
        "# Random Data Augmentation(Rescale) using ImageDataGenerator\n",
        "validation_data_generator = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "# Image Directory\n",
        "validation_image_directory = \"/content/PRO-M3-Pneumothorax-Image-Dataset/validation_dataset\"\n",
        "\n",
        "# Generate Preprocessed Augmented Data\n",
        "validation_augmented_images = validation_data_generator.flow_from_directory(\n",
        "    validation_image_directory,\n",
        "    target_size=(180,180))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TFZxDyWZjRb"
      },
      "source": [
        "#### Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUU7UKNhyftg",
        "outputId": "6061f8fb-c957-4887-fa8b-dc6722029976"
      },
      "source": [
        "training_augmented_images.class_indices"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'infected': 0, 'uninfected': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKguVEnx3O4m"
      },
      "source": [
        "## Convolutional Neural Network Architecture\n",
        "A CNN model have:\n",
        "\n",
        "1. **Feature Learning layers**:\n",
        "\n",
        "   1.1 Convolution + Activation(RELU) layers\n",
        "\n",
        "   1.2 Pooling layers\n",
        "\n",
        "2. **Classification layers**:\n",
        "\n",
        "   2.1 Flatten layer\n",
        "\n",
        "   2.2 Fully connected(Dense) layer \n",
        "\n",
        "   2.3 Fully connected(Dense) layer with Softmax\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/9d09af47-3a9d-48b7-a05c-8941009442ea.png\" width= 1500>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T-8YEZK3aj_"
      },
      "source": [
        "**Feature Extraction Visualisation(Convolution + Relu)**\n",
        "\n",
        "The convolution is a mathematical computation between two arrays, the image array and the filter array which gives a new image array.\n",
        "\n",
        "\n",
        "Visually we can understand that the feature detector/filter moves over the image to extract features from the image.\n",
        "\n",
        "\n",
        "\n",
        "[<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/3917c089-1d8f-4f32-b5c4-401b6abe8d47.gif\" width= 500>](https://)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHHUNrcWC91w"
      },
      "source": [
        "## Mathematically:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tQ9L7AzCXN3"
      },
      "source": [
        "**Conv2D Layer**\n",
        "\n",
        "The convolution is a mathematical computation between two 2D arrays, the image array and the filter array which gives a new image array.\n",
        "\n",
        "A portion of the input image array matrix, called a sub-array(size same as the size of the filter) is taken, starting from the top left.\n",
        "\n",
        "This sub-array is multiplied with the filter array. We can multiply one array matrix to another, by multiplying 1st element to 1st element of both the arrays(2nd element to 2nd element of both arrays and so on).\n",
        "\n",
        "After multiplying the result is added, which gives the value of the 1st element of the new image array.\n",
        "\n",
        "Then we shift towards right by one column, repeat the above steps to get the value of the 2nd element of the new array.\n",
        "\n",
        "Once the whole row is finished we shift downwards by one row, repeat the above steps to get the value of all elements of the new array one by one.\n",
        "\n",
        "The whole process is repeated with different filters, to get different output, which all together is the output of the 1st Conv2D layer.\n",
        "\n",
        "These outputs from the 1st Conv2D layer are given to the 2nd Conv2D layer and convolutions are performed.\n",
        "\n",
        "This repeated for all the layers of the CNN model.\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/306591ba-2163-45d9-9c60-dbc895332982.gif\" width= 800>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZhK3L6qCW0C"
      },
      "source": [
        "**ReLU**\n",
        "\n",
        "ReLU is defined as a function, y= f(x) such that it gives x for all values of x > 0 and 0 for all values of x<0.\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/6986c680-7ad3-4fad-bf04-59cecfa5e0e3.png\" width= 600>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yV1sDPWBZsS"
      },
      "source": [
        "**MaxPooling2D**\n",
        "\n",
        "First there is an input array(for example 4x4) and pool size(for example 2x2). Pool size is always smaller than the input array size.\n",
        "\n",
        "Then the maximum value is taken from the sub-array of size equal to pool size.\n",
        "\n",
        "The result after applying the Max Pooling will be the new array of size equal to the half of the size of the original input array.\n",
        "\n",
        "Since our input array is 4x4, after max pooling the new array will be 2x2, hence reducing the dimension of the array.\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/d485cb40-4db6-4fb6-9051-d9e888883053.jpg\" width= 800>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hMRvgb4W7MF"
      },
      "source": [
        "## Define Convolution Neural Network(CNN) Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVT96uWaZUtF"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',input_shape=(180,180,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(2,activation='softmax'),\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "8Vfuqy8hKAJq",
        "outputId": "dc2cb3c4-17a3-41bb-c869-28390364f7aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 178, 178, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 89, 89, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 87, 87, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 18, 18, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 10368)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10368)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               5308928   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,570,114\n",
            "Trainable params: 5,570,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuhJ_4N6XCle"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOj029YuZXRA"
      },
      "source": [
        "## ADD CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}